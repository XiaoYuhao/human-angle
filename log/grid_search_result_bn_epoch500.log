2020-10-25 22:50:42,686 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=5, learning_rate=0.000500
2020-10-25 22:51:42,703 logger DEBUG Epoch[0] loss:5.274443
2020-10-25 23:10:14,335 logger DEBUG Epoch[20] loss:3.029124
2020-10-25 23:28:59,137 logger DEBUG Epoch[40] loss:2.742396
2020-10-25 23:47:24,986 logger DEBUG Epoch[60] loss:2.601360
2020-10-26 00:06:02,942 logger DEBUG Epoch[80] loss:2.526139
2020-10-26 00:24:42,047 logger DEBUG Epoch[100] loss:2.446859
2020-10-26 00:43:22,988 logger DEBUG Epoch[120] loss:2.432024
2020-10-26 01:02:04,098 logger DEBUG Epoch[140] loss:2.435185
2020-10-26 01:20:36,399 logger DEBUG Epoch[160] loss:2.390101
2020-10-26 01:39:01,415 logger DEBUG Epoch[180] loss:2.314542
2020-10-26 01:57:48,697 logger DEBUG Epoch[200] loss:2.298494
2020-10-26 02:16:29,069 logger DEBUG Epoch[220] loss:2.307046
2020-10-26 02:35:08,707 logger DEBUG Epoch[240] loss:2.265989
2020-10-26 02:53:58,331 logger DEBUG Epoch[260] loss:2.281868
2020-10-26 03:12:30,484 logger DEBUG Epoch[280] loss:2.223046
2020-10-26 03:31:09,760 logger DEBUG Epoch[300] loss:1.968650
2020-10-26 03:49:51,214 logger DEBUG Epoch[320] loss:1.817324
2020-10-26 04:07:36,858 logger DEBUG Epoch[340] loss:1.770772
2020-10-26 04:25:51,094 logger DEBUG Epoch[360] loss:1.749037
2020-10-26 04:44:26,464 logger DEBUG Epoch[380] loss:1.752857
2020-10-26 05:01:55,349 logger DEBUG Epoch[400] loss:1.761116
2020-10-26 05:19:27,495 logger DEBUG Epoch[420] loss:1.718914
2020-10-26 05:37:09,973 logger DEBUG Epoch[440] loss:1.753482
2020-10-26 05:55:14,852 logger DEBUG Epoch[460] loss:1.711645
2020-10-26 06:13:32,734 logger DEBUG Epoch[480] loss:1.719633
2020-10-26 06:30:21,989 logger DEBUG training finish.
2020-10-26 06:30:21,990 logger DEBUG  
 
 

2020-10-26 06:30:22,208 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=10, learning_rate=0.000500
2020-10-26 06:30:49,942 logger DEBUG Epoch[0] loss:3.887232
2020-10-26 06:39:23,163 logger DEBUG Epoch[20] loss:1.598774
2020-10-26 06:47:32,669 logger DEBUG Epoch[40] loss:1.620193
2020-10-26 06:56:05,862 logger DEBUG Epoch[60] loss:1.422531
2020-10-26 07:04:45,225 logger DEBUG Epoch[80] loss:1.292361
2020-10-26 07:13:01,228 logger DEBUG Epoch[100] loss:1.241174
2020-10-26 07:21:15,379 logger DEBUG Epoch[120] loss:1.148776
2020-10-26 07:29:49,126 logger DEBUG Epoch[140] loss:1.130339
2020-10-26 07:38:22,361 logger DEBUG Epoch[160] loss:1.138903
2020-10-26 07:46:50,046 logger DEBUG Epoch[180] loss:1.128841
2020-10-26 07:55:27,766 logger DEBUG Epoch[200] loss:1.056200
2020-10-26 08:04:06,225 logger DEBUG Epoch[220] loss:1.119959
2020-10-26 08:12:36,706 logger DEBUG Epoch[240] loss:1.136784
2020-10-26 08:21:11,867 logger DEBUG Epoch[260] loss:1.068887
2020-10-26 08:29:13,041 logger DEBUG Epoch[280] loss:1.043228
2020-10-26 08:37:46,900 logger DEBUG Epoch[300] loss:0.913503
2020-10-26 08:46:09,925 logger DEBUG Epoch[320] loss:0.844211
2020-10-26 08:54:45,909 logger DEBUG Epoch[340] loss:0.838275
2020-10-26 09:03:17,832 logger DEBUG Epoch[360] loss:0.815032
2020-10-26 09:11:56,325 logger DEBUG Epoch[380] loss:0.807020
2020-10-26 09:20:31,123 logger DEBUG Epoch[400] loss:0.802805
2020-10-26 09:29:03,911 logger DEBUG Epoch[420] loss:0.806969
2020-10-26 09:37:38,001 logger DEBUG Epoch[440] loss:0.794500
2020-10-26 09:46:10,655 logger DEBUG Epoch[460] loss:0.800966
2020-10-26 09:54:48,000 logger DEBUG Epoch[480] loss:0.792487
2020-10-26 10:02:57,121 logger DEBUG training finish.
2020-10-26 10:02:57,121 logger DEBUG  
 
 

2020-10-26 10:02:57,293 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=20, learning_rate=0.000500
2020-10-26 10:03:10,685 logger DEBUG Epoch[0] loss:2.845465
2020-10-26 10:07:03,236 logger DEBUG Epoch[20] loss:0.678269
2020-10-26 10:11:09,459 logger DEBUG Epoch[40] loss:0.617143
2020-10-26 10:15:04,760 logger DEBUG Epoch[60] loss:0.572432
2020-10-26 10:19:15,564 logger DEBUG Epoch[80] loss:0.560377
2020-10-26 10:23:22,966 logger DEBUG Epoch[100] loss:0.525146
2020-10-26 10:27:35,508 logger DEBUG Epoch[120] loss:0.507948
2020-10-26 10:32:00,471 logger DEBUG Epoch[140] loss:0.482687
2020-10-26 10:36:26,173 logger DEBUG Epoch[160] loss:0.505405
2020-10-26 10:40:52,077 logger DEBUG Epoch[180] loss:0.474768
2020-10-26 10:45:15,725 logger DEBUG Epoch[200] loss:0.493224
2020-10-26 10:49:38,824 logger DEBUG Epoch[220] loss:0.483403
2020-10-26 10:54:02,821 logger DEBUG Epoch[240] loss:0.483020
2020-10-26 10:58:25,421 logger DEBUG Epoch[260] loss:0.462504
2020-10-26 11:02:50,232 logger DEBUG Epoch[280] loss:0.485267
2020-10-26 11:07:16,751 logger DEBUG Epoch[300] loss:0.425882
2020-10-26 11:11:43,004 logger DEBUG Epoch[320] loss:0.390467
2020-10-26 11:16:13,678 logger DEBUG Epoch[340] loss:0.383747
2020-10-26 11:20:41,329 logger DEBUG Epoch[360] loss:0.384440
2020-10-26 11:25:08,801 logger DEBUG Epoch[380] loss:0.376490
2020-10-26 11:29:32,933 logger DEBUG Epoch[400] loss:0.384410
2020-10-26 11:34:00,093 logger DEBUG Epoch[420] loss:0.375901
2020-10-26 11:38:25,211 logger DEBUG Epoch[440] loss:0.377970
2020-10-26 11:42:49,284 logger DEBUG Epoch[460] loss:0.377745
2020-10-26 11:47:15,120 logger DEBUG Epoch[480] loss:0.380856
2020-10-26 11:51:24,944 logger DEBUG training finish.
2020-10-26 11:51:24,944 logger DEBUG  
 
 

2020-10-26 11:51:25,074 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=50, learning_rate=0.000500
2020-10-26 11:51:31,084 logger DEBUG Epoch[0] loss:2.233350
2020-10-26 11:53:24,646 logger DEBUG Epoch[20] loss:0.309330
2020-10-26 11:55:22,497 logger DEBUG Epoch[40] loss:0.264955
2020-10-26 11:57:20,693 logger DEBUG Epoch[60] loss:0.244678
2020-10-26 11:59:17,320 logger DEBUG Epoch[80] loss:0.228483
2020-10-26 12:01:13,968 logger DEBUG Epoch[100] loss:0.217282
2020-10-26 12:03:10,455 logger DEBUG Epoch[120] loss:0.212718
2020-10-26 12:05:07,862 logger DEBUG Epoch[140] loss:0.207357
2020-10-26 12:07:03,283 logger DEBUG Epoch[160] loss:0.211093
2020-10-26 12:09:00,908 logger DEBUG Epoch[180] loss:0.202037
2020-10-26 12:10:58,757 logger DEBUG Epoch[200] loss:0.212905
2020-10-26 12:12:54,320 logger DEBUG Epoch[220] loss:0.202445
2020-10-26 12:14:52,628 logger DEBUG Epoch[240] loss:0.210340
2020-10-26 12:16:49,437 logger DEBUG Epoch[260] loss:0.200346
2020-10-26 12:18:46,169 logger DEBUG Epoch[280] loss:0.193631
2020-10-26 12:20:43,143 logger DEBUG Epoch[300] loss:0.177919
2020-10-26 12:22:38,987 logger DEBUG Epoch[320] loss:0.172900
2020-10-26 12:24:35,852 logger DEBUG Epoch[340] loss:0.174972
2020-10-26 12:26:30,476 logger DEBUG Epoch[360] loss:0.171890
2020-10-26 12:28:28,082 logger DEBUG Epoch[380] loss:0.174948
2020-10-26 12:30:23,762 logger DEBUG Epoch[400] loss:0.170423
2020-10-26 12:32:19,279 logger DEBUG Epoch[420] loss:0.170002
2020-10-26 12:34:16,496 logger DEBUG Epoch[440] loss:0.168957
2020-10-26 12:36:11,490 logger DEBUG Epoch[460] loss:0.162550
2020-10-26 12:38:08,457 logger DEBUG Epoch[480] loss:0.166851
2020-10-26 12:39:59,568 logger DEBUG training finish.
2020-10-26 12:39:59,568 logger DEBUG  
 
 

2020-10-26 12:39:59,691 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=100, learning_rate=0.000500
2020-10-26 12:40:03,691 logger DEBUG Epoch[0] loss:2.192286
2020-10-26 12:41:10,625 logger DEBUG Epoch[20] loss:0.216041
2020-10-26 12:42:17,781 logger DEBUG Epoch[40] loss:0.179748
2020-10-26 12:43:24,004 logger DEBUG Epoch[60] loss:0.148289
2020-10-26 12:44:30,540 logger DEBUG Epoch[80] loss:0.136704
2020-10-26 12:45:38,538 logger DEBUG Epoch[100] loss:0.146974
2020-10-26 12:46:45,926 logger DEBUG Epoch[120] loss:0.139572
2020-10-26 12:47:52,141 logger DEBUG Epoch[140] loss:0.134069
2020-10-26 12:48:56,869 logger DEBUG Epoch[160] loss:0.128076
2020-10-26 12:50:02,458 logger DEBUG Epoch[180] loss:0.127497
2020-10-26 12:51:09,599 logger DEBUG Epoch[200] loss:0.123577
2020-10-26 12:52:14,874 logger DEBUG Epoch[220] loss:0.119060
2020-10-26 12:53:22,359 logger DEBUG Epoch[240] loss:0.121696
2020-10-26 12:54:28,927 logger DEBUG Epoch[260] loss:0.120384
2020-10-26 12:55:34,861 logger DEBUG Epoch[280] loss:0.120936
2020-10-26 12:56:40,355 logger DEBUG Epoch[300] loss:0.109225
2020-10-26 12:57:47,723 logger DEBUG Epoch[320] loss:0.103810
2020-10-26 12:58:54,146 logger DEBUG Epoch[340] loss:0.106083
2020-10-26 13:00:01,131 logger DEBUG Epoch[360] loss:0.104368
2020-10-26 13:01:07,635 logger DEBUG Epoch[380] loss:0.105325
2020-10-26 13:02:14,117 logger DEBUG Epoch[400] loss:0.105015
2020-10-26 13:03:17,247 logger DEBUG Epoch[420] loss:0.105573
2020-10-26 13:04:20,726 logger DEBUG Epoch[440] loss:0.107362
2020-10-26 13:05:27,331 logger DEBUG Epoch[460] loss:0.104505
2020-10-26 13:06:35,185 logger DEBUG Epoch[480] loss:0.108210
2020-10-26 13:07:38,415 logger DEBUG training finish.
2020-10-26 13:07:38,416 logger DEBUG  
 
 

2020-10-26 13:07:38,512 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=200, learning_rate=0.000500
2020-10-26 13:07:40,898 logger DEBUG Epoch[0] loss:2.544584
2020-10-26 13:08:16,187 logger DEBUG Epoch[20] loss:0.181114
2020-10-26 13:08:51,485 logger DEBUG Epoch[40] loss:0.131494
2020-10-26 13:09:26,648 logger DEBUG Epoch[60] loss:0.108988
2020-10-26 13:10:01,912 logger DEBUG Epoch[80] loss:0.096791
2020-10-26 13:10:36,918 logger DEBUG Epoch[100] loss:0.105607
2020-10-26 13:11:09,363 logger DEBUG Epoch[120] loss:0.099132
2020-10-26 13:11:44,220 logger DEBUG Epoch[140] loss:0.097001
2020-10-26 13:12:19,741 logger DEBUG Epoch[160] loss:0.088005
2020-10-26 13:12:54,583 logger DEBUG Epoch[180] loss:0.084538
2020-10-26 13:13:29,083 logger DEBUG Epoch[200] loss:0.091793
2020-10-26 13:14:04,703 logger DEBUG Epoch[220] loss:0.086309
2020-10-26 13:14:39,597 logger DEBUG Epoch[240] loss:0.085516
2020-10-26 13:15:14,830 logger DEBUG Epoch[260] loss:0.088252
2020-10-26 13:15:50,558 logger DEBUG Epoch[280] loss:0.085168
2020-10-26 13:16:25,703 logger DEBUG Epoch[300] loss:0.079087
2020-10-26 13:17:00,849 logger DEBUG Epoch[320] loss:0.078081
2020-10-26 13:17:36,087 logger DEBUG Epoch[340] loss:0.073433
2020-10-26 13:18:11,437 logger DEBUG Epoch[360] loss:0.077949
2020-10-26 13:18:47,149 logger DEBUG Epoch[380] loss:0.073940
2020-10-26 13:19:22,000 logger DEBUG Epoch[400] loss:0.076113
2020-10-26 13:19:57,189 logger DEBUG Epoch[420] loss:0.074791
2020-10-26 13:20:32,125 logger DEBUG Epoch[440] loss:0.074407
2020-10-26 13:21:07,271 logger DEBUG Epoch[460] loss:0.071421
2020-10-26 13:21:42,188 logger DEBUG Epoch[480] loss:0.075424
2020-10-26 13:22:15,776 logger DEBUG training finish.
2020-10-26 13:22:15,776 logger DEBUG  
 
 

2020-10-26 13:22:15,865 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=500, learning_rate=0.000500
2020-10-26 13:22:17,320 logger DEBUG Epoch[0] loss:3.948012
2020-10-26 13:22:35,714 logger DEBUG Epoch[20] loss:0.150319
2020-10-26 13:22:54,294 logger DEBUG Epoch[40] loss:0.112927
2020-10-26 13:23:12,566 logger DEBUG Epoch[60] loss:0.097735
2020-10-26 13:23:30,609 logger DEBUG Epoch[80] loss:0.080009
2020-10-26 13:23:48,862 logger DEBUG Epoch[100] loss:0.078468
2020-10-26 13:24:06,742 logger DEBUG Epoch[120] loss:0.078930
2020-10-26 13:24:25,185 logger DEBUG Epoch[140] loss:0.086578
2020-10-26 13:24:43,527 logger DEBUG Epoch[160] loss:0.083807
2020-10-26 13:25:02,367 logger DEBUG Epoch[180] loss:0.069972
2020-10-26 13:25:20,918 logger DEBUG Epoch[200] loss:0.067859
2020-10-26 13:25:39,318 logger DEBUG Epoch[220] loss:0.067873
2020-10-26 13:25:57,140 logger DEBUG Epoch[240] loss:0.062619
2020-10-26 13:26:15,888 logger DEBUG Epoch[260] loss:0.066435
2020-10-26 13:26:33,915 logger DEBUG Epoch[280] loss:0.071151
2020-10-26 13:26:52,455 logger DEBUG Epoch[300] loss:0.064406
2020-10-26 13:27:10,644 logger DEBUG Epoch[320] loss:0.056708
2020-10-26 13:27:29,422 logger DEBUG Epoch[340] loss:0.057286
2020-10-26 13:27:47,801 logger DEBUG Epoch[360] loss:0.055419
2020-10-26 13:28:05,781 logger DEBUG Epoch[380] loss:0.057939
2020-10-26 13:28:23,858 logger DEBUG Epoch[400] loss:0.055633
2020-10-26 13:28:42,270 logger DEBUG Epoch[420] loss:0.055893
2020-10-26 13:29:00,814 logger DEBUG Epoch[440] loss:0.056108
2020-10-26 13:29:18,859 logger DEBUG Epoch[460] loss:0.055524
2020-10-26 13:29:36,643 logger DEBUG Epoch[480] loss:0.056251
2020-10-26 13:29:54,254 logger DEBUG training finish.
2020-10-26 13:29:54,254 logger DEBUG  
 
 

2020-10-26 13:29:54,341 logger DEBUG hidden_layers=5, hidden_size=1024, batch_size=1000, learning_rate=0.000500
2020-10-26 13:29:55,581 logger DEBUG Epoch[0] loss:5.404413
2020-10-26 13:30:08,596 logger DEBUG Epoch[20] loss:0.170702
2020-10-26 13:30:21,634 logger DEBUG Epoch[40] loss:0.113236
2020-10-26 13:30:34,162 logger DEBUG Epoch[60] loss:0.091254
2020-10-26 13:30:47,066 logger DEBUG Epoch[80] loss:0.081263
2020-10-26 13:31:00,219 logger DEBUG Epoch[100] loss:0.077573
2020-10-26 13:31:13,312 logger DEBUG Epoch[120] loss:0.073044
2020-10-26 13:31:26,156 logger DEBUG Epoch[140] loss:0.071927
2020-10-26 13:31:39,078 logger DEBUG Epoch[160] loss:0.067172
2020-10-26 13:31:52,271 logger DEBUG Epoch[180] loss:0.081468
2020-10-26 13:32:05,203 logger DEBUG Epoch[200] loss:0.061575
2020-10-26 13:32:18,289 logger DEBUG Epoch[220] loss:0.067836
2020-10-26 13:32:31,459 logger DEBUG Epoch[240] loss:0.061201
2020-10-26 13:32:44,222 logger DEBUG Epoch[260] loss:0.100971
2020-10-26 13:32:56,706 logger DEBUG Epoch[280] loss:0.057682
2020-10-26 13:33:09,849 logger DEBUG Epoch[300] loss:0.056119
2020-10-26 13:33:23,122 logger DEBUG Epoch[320] loss:0.051465
2020-10-26 13:33:35,889 logger DEBUG Epoch[340] loss:0.050842
2020-10-26 13:33:48,881 logger DEBUG Epoch[360] loss:0.050116
2020-10-26 13:34:01,888 logger DEBUG Epoch[380] loss:0.049932
2020-10-26 13:34:15,169 logger DEBUG Epoch[400] loss:0.050242
2020-10-26 13:34:28,197 logger DEBUG Epoch[420] loss:0.049211
2020-10-26 13:34:41,386 logger DEBUG Epoch[440] loss:0.050115
2020-10-26 13:34:54,349 logger DEBUG Epoch[460] loss:0.050434
2020-10-26 13:35:07,271 logger DEBUG Epoch[480] loss:0.050919
2020-10-26 13:35:19,374 logger DEBUG training finish.
2020-10-26 13:35:19,375 logger DEBUG  
 
 

